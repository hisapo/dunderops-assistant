"""
DunderOps Assistant com Chain of Verification
Vers√£o melhorada que usa auto-cr√≠tica para aumentar assertividade das respostas
"""

import json
import os
from openai import OpenAI
from src.core.functions import (
    schedule_meeting,
    generate_paper_quote,
    prank_dwight,
)
from abstra.forms import TextareaInput, MarkdownOutput, run
from src.core.prompt_config import PromptConfig
from src.core.function_intent import detect_function_intent
from src.core.function_validator import FunctionValidator
from src.cov.chain_of_verification import ChainOfVerification, CoVConfiguration
from src.core.metrics_tracker import MetricsTracker

print("üöÄ Iniciando DunderOps Assistant com Chain of Verification...")

# Configura√ß√£o
prompts = PromptConfig()
validator = FunctionValidator(prompts)
cov_config = CoVConfiguration()

# Welcome message espec√≠fico desta UI
welcome_text = """
# DunderOps Assistant (+CoVe)

Ol√°! Eu sou o assistente de opera√ß√µes da Dunder Mifflin Paper Co! Eu posso te responder trivia sobre The Office, ajudar em coisas como: preparar or√ßamentos, agendar reuni√µes, e at√© planejar trotes para o Dwight üòá

üîç **Chain of Verification Ativo:** Esta vers√£o usa auto-verifica√ß√£o para dar respostas mais precisas!
"""

input_page = [
    MarkdownOutput(welcome_text),
    TextareaInput(label="Como posso te ajudar hoje?", key="textarea_input"),
]

# Pegar o input do usuario
result = run([input_page])
user_input = result["textarea_input"]
print(f"üí¨ Usu√°rio perguntou: {user_input}")

# Configura cliente OpenAI
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key:
    error_message = "‚ùå Erro: API Key da OpenAI n√£o configurada. Por favor, configure a vari√°vel de ambiente OPENAI_API_KEY."
    final_page = [MarkdownOutput(error_message)]
    run([final_page])
    exit(1)

client = OpenAI(api_key=openai_api_key)

# Inicializa Chain of Verification
cov = ChainOfVerification(client, prompts)

# Inicializa metrics tracker
tracker = MetricsTracker("chain_of_verification")
execution_id = tracker.start_execution(user_input)

try:
    # Carrega o manifesto com os schemas
    with open("config/manifest.json") as f:
        manifest = json.load(f)

    # Mapeia nome ‚Üí fun√ß√£o em functions.py
    LOCAL_FUNCS = {
        "schedule_meeting": schedule_meeting,
        "generate_paper_quote": generate_paper_quote,
        "prank_dwight": prank_dwight,
    }

    # ETAPA 1: Gera resposta inicial
    # Detecta se deve for√ßar function calling
    tool_choice = detect_function_intent(user_input)
    print(f"üéØ Detec√ß√£o de inten√ß√£o: {tool_choice}")
    
    print("ü§ñ Enviando pergunta para a OpenAI (resposta inicial)...")
    first_response = client.chat.completions.create(
        model="gpt-4o-mini",
        tools=manifest["tools"],
        tool_choice=tool_choice,
        messages=[
            {"role": "system", "content": prompts.system_prompt},
            {"role": "user", "content": user_input}
        ]
    )

    # Registra primeira chamada de API
    tracker.track_api_call(
        input_tokens=first_response.usage.prompt_tokens,
        output_tokens=first_response.usage.completion_tokens
    )

    msg = first_response.choices[0].message
    function_call_info = None
    function_result = None
    initial_response = ""

    # Processa resposta inicial
    if msg.tool_calls:
        print("üîß AI decidiu usar uma fun√ß√£o...")
        call = msg.tool_calls[0]
        name = call.function.name
        args = json.loads(call.function.arguments)
        
        function_call_info = {
            "name": name,
            "arguments": args,
            "call_object": call
        }

        print(f"üîß Validando fun√ß√£o: {name} com argumentos: {args}")

        # Valida se todos os par√¢metros necess√°rios est√£o presentes
        is_valid, humor_message = validator.validate_function_params(name, args)
        
        if not is_valid:
            print("‚ùå Par√¢metros incompletos - respondendo com humor...")
            initial_response = humor_message
            
            # Registra chamada de fun√ß√£o (falhou na valida√ß√£o)
            tracker.track_function_call(name, args, None, False)
        else:
            print("‚úÖ Par√¢metros v√°lidos - executando fun√ß√£o...")
            # Executa a fun√ß√£o
            function_result = LOCAL_FUNCS[name](**args)
            print(f"‚úÖ Resultado da fun√ß√£o: {function_result}")

            # Registra chamada de fun√ß√£o (sucesso)
            tracker.track_function_call(name, args, function_result, True)

            # Gera resposta final baseada no resultado da fun√ß√£o
            print("üí≠ Gerando resposta baseada no resultado da fun√ß√£o...")
            final_response_call = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": prompts.final_system_prompt},
                    {"role": "user", "content": user_input},
                    {"role": "assistant", "content": None, "tool_calls": [call]},
                    {
                        "role": "tool",
                        "tool_call_id": call.id,
                        "name": name,
                        "content": json.dumps(function_result)
                    }
                ]
            )
            
            # Registra segunda chamada de API
            tracker.track_api_call(
                input_tokens=final_response_call.usage.prompt_tokens,
                output_tokens=final_response_call.usage.completion_tokens
            )
            
            initial_response = final_response_call.choices[0].message.content
    else:
        print("üí¨ AI respondeu diretamente sem usar fun√ß√µes...")
        initial_response = msg.content

    print(f"üìù Resposta inicial: {initial_response}")

    # ETAPA 2: Chain of Verification
    if cov_config.should_verify(function_call_info.get("name") if function_call_info else None):
        print("üîç Aplicando Chain of Verification...")
        
        # Inicia fase de verifica√ß√£o no tracker
        tracker.start_verification_phase()
        
        # Executa verifica√ß√£o e poss√≠vel corre√ß√£o
        final_response, verification_metadata = cov.process_with_verification(
            user_input=user_input,
            initial_response=initial_response,
            function_call=function_call_info
        )
        
        # Simula tokens da verifica√ß√£o (em implementa√ß√£o real, seria calculado)
        verification_tokens = len(verification_metadata.get("verification_result", {}).get("issues", [])) * 50
        
        # Finaliza fase de verifica√ß√£o no tracker
        tracker.end_verification_phase(
            verification_tokens=verification_tokens,
            correction_made=verification_metadata.get("correction_applied", False)
        )
        
        if verification_metadata.get("correction_applied", False):
            print("‚úÖ Resposta foi melhorada pelo Chain of Verification")
        else:
            print("‚úÖ Resposta inicial aprovada na verifica√ß√£o")
            
    else:
        print("‚è≠Ô∏è Verifica√ß√£o pulada para este tipo de resposta")
        final_response = initial_response

    print(f"üéØ Resposta final: {final_response}")

except Exception as e:
    print(f"‚ùå Erro durante execu√ß√£o: {str(e)}")
    tracker.track_error(str(e))
    final_response = f"‚ùå Desculpe, ocorreu um erro: {str(e)}"

finally:
    # Finaliza tracking de m√©tricas
    try:
        metric_data = tracker.end_execution(final_response)
        print(f"üìä M√©tricas coletadas - ID: {metric_data.execution_id}")
        print(f"   ‚Ä¢ Tokens totais: {metric_data.total_tokens}")
        print(f"   ‚Ä¢ Lat√™ncia: {metric_data.total_latency_ms:.2f}ms")
        print(f"   ‚Ä¢ Verifica√ß√£o usada: {metric_data.verification_used}")
        print(f"   ‚Ä¢ Corre√ß√£o aplicada: {metric_data.correction_made}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao finalizar m√©tricas: {str(e)}")

# Exibe a resposta final para o usu√°rio
final_page = [MarkdownOutput(final_response)]
run([final_page])
