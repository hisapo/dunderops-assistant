import json
import os
from openai import OpenAI
from src.core.functions import (
    schedule_meeting,
    generate_paper_quote,
    prank_dwight,
)
from abstra.forms import TextareaInput, MarkdownOutput, run
from src.core.prompt_config import PromptConfig
from src.core.function_validator import FunctionValidator
from src.core.function_intent import detect_function_intent

print("üöÄ Iniciando DunderOps Assistant...")

# Load prompt configuration
prompts = PromptConfig()
validator = FunctionValidator(prompts)

# Welcome message espec√≠fico desta UI
welcome_text = """
# DunderOps Assistant

Ol√°! Eu sou o assistente de opera√ß√µes da Dunder Mifflin Paper Co! Eu posso te responder trivia sobre The Office, ajudar em coisas como: preparar or√ßamentos, agendar reuni√µes, e at√© planejar trotes para o Dwight üòá 
"""

input_page = [
    MarkdownOutput(welcome_text),
    TextareaInput(label="Como posso te ajudar hoje?", key="textarea_input"),
]

# Pegar o input do usuario
result = run([input_page])
user_input = result["textarea_input"]
print(f"üí¨ Usu√°rio perguntou: {user_input}")

# Configura cliente OpenAI com vari√°vel de ambiente 
openai_api_key = os.environ.get("OPENAI_API_KEY")

client = OpenAI(api_key=openai_api_key)

# Carrega o manifesto com os schemas
with open("config/manifest.json") as f:
    manifest = json.load(f)

# Mapeia nome ‚Üí fun√ß√£o em functions.py
LOCAL_FUNCS = {
    "schedule_meeting": schedule_meeting,
    "generate_paper_quote": generate_paper_quote,
    "prank_dwight": prank_dwight,
}

# Detecta se deve for√ßar function calling
tool_choice = detect_function_intent(user_input)
print(f"üéØ Detec√ß√£o de inten√ß√£o: {tool_choice}")

# Envia a mensagem do usu√°rio para o modelo j√° com os schemas
print("ü§ñ Enviando pergunta para a OpenAI...")
first = client.chat.completions.create(
    model="gpt-4o-mini",
    tools=manifest["tools"],
    tool_choice=tool_choice,
    messages=[
        {"role": "system", "content": prompts.system_prompt},
        {"role": "user", "content": user_input}
    ]
)

msg = first.choices[0].message

# Checa se a AI decidiu chamar uma fun√ß√£o
if msg.tool_calls:
    print("üîß AI decidiu usar uma fun√ß√£o...")
    call = msg.tool_calls[0]
    name = call.function.name
    args = json.loads(call.function.arguments)

    print(f"üîß Validando fun√ß√£o: {name} com argumentos: {args}")

    # Valida se todos os par√¢metros necess√°rios est√£o presentes
    is_valid, humor_message = validator.validate_function_params(name, args)
    
    if not is_valid:
        print("‚ùå Par√¢metros incompletos - respondendo com humor...")
        # Se par√¢metros est√£o faltando, usa resposta humor√≠stica
        final_response = humor_message
    else:
        print("‚úÖ Par√¢metros v√°lidos - executando fun√ß√£o...")
        # Executa a fun√ß√£o
        function_result = LOCAL_FUNCS[name](**args)
        print(f"‚úÖ Resultado da fun√ß√£o: {function_result}")

        # Devolve o resultado como mensagem "tool" e pede a resposta final
        print("üí≠ Gerando resposta final...")
        second = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompts.final_system_prompt},
                {"role": "user", "content": user_input},
                {"role": "assistant", "content": None, "tool_calls": [call]},
                {
                    "role": "tool",
                    "tool_call_id": call.id,
                    "name": name,
                    "content": json.dumps(function_result)
                }
            ]
        )
        final_response = second.choices[0].message.content
else:
    print("üí¨ AI respondeu diretamente sem usar fun√ß√µes...")
    # A IA respondeu diretamente sem chamar fun√ß√µes
    final_response = msg.content

print(f"üéØ Resposta final gerada: {final_response}")

# Exibe a resposta final para o usu√°rio
final_page = [MarkdownOutput(final_response)]
run([final_page])